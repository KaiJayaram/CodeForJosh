{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    f = open(gloveFile,'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "glove = loadGloveModel('glove50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                               text author\n",
      "count     19579                                              19579  19579\n",
      "unique    19579                                              19579      3\n",
      "top     id15892  A shriek had been heard by a neighbour during ...    EAP\n",
      "freq          1                                                  1   7900\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This process, however, afforded me no means of...\n",
       "1    It never once occurred to me that the fumbling...\n",
       "2    In his left hand was a gold snuff box, from wh...\n",
       "3    How lovely is spring As we looked from Windsor...\n",
       "4    Finding nothing else, not even gold, the Super...\n",
       "5    A youth passed in solitude, my best years spen...\n",
       "6    The astronomer, perhaps, at this point, took r...\n",
       "7          The surcingle hung in ribands from my body.\n",
       "8    I knew that you could not say to yourself 'ste...\n",
       "9    I confess that neither the structure of langua...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "text = np.array(text)\n",
    "vocab = set()\n",
    "\n",
    "for t in text:\n",
    "    for c in t.lower().split():\n",
    "        vocab.add(c)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)\n",
    "char_id = {}\n",
    "for (a,b) in zip(vocab,range(vocab_len)):\n",
    "    char_id[a] = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cf2258588731>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         return (torch.zeros(1, 1, self.hidden_dim),\n\u001b[0;32m     21\u001b[0m                 torch.zeros(1, 1, self.hidden_dim))\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mrnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.l2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "rnn = RNN(50, 50, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "word_id = {}\n",
    "id_word = {}\n",
    "for a,b in zip(vocab,range(len(vocab))):\n",
    "    word_id[a] = b\n",
    "    id_word[b] = a\n",
    "def char_tensor(char):\n",
    "    ide = char_id[char]\n",
    "    tensor = torch.zeros(1, vocab_len)\n",
    "    tensor[0][ide] = 1\n",
    "    return tensor\n",
    "def word_tensor(word):\n",
    "    tensor = []\n",
    "    word = word.lower()\n",
    "    if word in glove:\n",
    "        tensor = torch.from_numpy(glove[word])\n",
    "    return tensor\n",
    "def cat_tensor(word):\n",
    "    ide = word_id[word]\n",
    "    tensor = torch.zeros(1, len(vocab), dtype=torch.long)\n",
    "    tensor[0][ide] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_tensor(sentence):\n",
    "    tensor = torch.zeros(len(sentence), 1, vocab_len)\n",
    "    for li, char in enumerate(sentence):\n",
    "        if char in char_id:\n",
    "            tensor[li][0] = char_tensor(char)\n",
    "    return tensor\n",
    "def glove_tensor(sentence):\n",
    "    tensor = torch.zeros(len(sentence), 1, 50)\n",
    "    for li, word in enumerate(sentence):\n",
    "        if word in glove:\n",
    "            tensor[li][0] = word_tensor(word)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = glove_tensor('Hi, How Are ')\n",
    "hidden = torch.zeros(1, 50)\n",
    "category = word_tensor('You')\n",
    "output, next_hidden = rnn(input[0], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_from_id = {}\n",
    "for a in char_id:\n",
    "    char_from_id[char_id[a]] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atom,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def charFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return char_from_id[category_i]\n",
    "def wordFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return id_word[category_i]\n",
    "wordFromOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(line_tensor, hidden, ct):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, ct)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, hidden, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "train_target = []\n",
    "for t in text: \n",
    "    t= t.lower().split()\n",
    "    for i in range(len(t)-4):\n",
    "        train_sentences.append((t[i], t[i+1],t[i+2], t[i+3]))\n",
    "        train_target.append(t[i+4])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('of',\n",
       " ('accidental', 'bias', 'in', 'favor'),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([[[ 0.6659, -0.2444, -0.2312,  0.1157, -0.2919,  1.6577,  0.4665,\n",
       "            0.7202,  0.8835,  0.7989,  0.0485, -0.2027,  0.3217,  0.2207,\n",
       "            0.9803, -0.3313, -0.2948, -0.0060, -1.3117,  0.1120,  0.1062,\n",
       "            0.0740,  0.0512, -0.2042,  0.5494, -1.2395, -0.3544,  0.2456,\n",
       "            1.5295,  0.6477,  0.7384, -0.6622, -0.0772, -0.5575,  0.3594,\n",
       "            0.5344,  0.7772, -0.8527,  0.1012,  0.6029, -0.2707,  0.2990,\n",
       "            0.1640,  0.2448,  0.7822, -0.2064, -0.0065,  0.9383,  0.7737,\n",
       "           -0.2267]],\n",
       " \n",
       "         [[-1.0211, -0.3856, -0.5580, -0.3775, -0.1599,  1.3789,  1.0915,\n",
       "           -0.4825,  0.0263,  0.1154,  0.2458, -0.7423, -0.5669, -0.5638,\n",
       "           -0.1779,  0.3422,  0.0260, -0.9077,  0.2206, -0.8413, -0.1929,\n",
       "            0.1826,  0.2162,  0.5358, -0.6155, -1.4210, -0.7049,  0.6912,\n",
       "            0.1499,  0.2290,  1.2750,  0.1500,  0.0653, -1.5946, -0.6198,\n",
       "           -0.7370, -0.4226, -0.7451, -0.2257, -0.2782,  0.4051,  0.4132,\n",
       "           -0.0186,  0.8630,  0.0024, -0.8119,  0.5207,  1.1772,  0.7386,\n",
       "           -0.0811]],\n",
       " \n",
       "         [[ 0.3304,  0.2500, -0.6087,  0.1092,  0.0364,  0.1510, -0.5508,\n",
       "           -0.0742, -0.0923, -0.3282,  0.0960, -0.8227, -0.3672, -0.6701,\n",
       "            0.4291,  0.0165, -0.2357,  0.1286, -1.0953,  0.4333,  0.5707,\n",
       "           -0.1036,  0.2042,  0.0783, -0.4279, -1.7984, -0.2786,  0.1195,\n",
       "           -0.1269,  0.0317,  3.8631, -0.1779, -0.0824, -0.6270,  0.2650,\n",
       "           -0.0572, -0.0735,  0.4610,  0.3086,  0.1250, -0.4861, -0.0080,\n",
       "            0.0312, -0.3658, -0.4270,  0.4216, -0.1167, -0.5070, -0.0273,\n",
       "           -0.5329]],\n",
       " \n",
       "         [[-0.5492, -0.4882,  0.0105, -0.3934, -0.0861,  0.6218, -0.2574,\n",
       "           -0.1247, -0.9434,  0.7289, -0.2288, -0.3638,  0.0006, -0.0396,\n",
       "           -0.2491,  0.1860,  0.0844, -0.9286,  0.5142, -0.7319, -0.1047,\n",
       "           -0.0761, -0.0440, -0.1493, -0.2536, -1.4151,  0.1869, -0.1722,\n",
       "            0.1911,  0.0885,  2.3957,  0.2837, -0.8142, -0.2647,  0.1384,\n",
       "           -1.2527, -0.0516,  0.3833, -0.9281, -0.3447, -0.4486, -0.0460,\n",
       "            0.4259,  0.6249, -0.6696,  0.1220, -0.9852,  0.0270,  0.0773,\n",
       "            0.3021]]]),\n",
       " tensor([30308]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def randomTrainingExample():\n",
    "    i = random.randint(0,len(train_sentences)-1)\n",
    "    category = train_target[i]\n",
    "    line = train_sentences[i]\n",
    "    line_tensor = glove_tensor(line)\n",
    "    if len(line_tensor) == 0:\n",
    "        return randomTrainingExample()\n",
    "    category_tensor = cat_tensor(category)\n",
    "    ct = torch.tensor([word_id[category]], dtype=torch.long)\n",
    "    return category, line, category_tensor, line_tensor, ct\n",
    "randomTrainingExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 7GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:204",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2e4a22808aef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomTrainingExample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b320b25e81c6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(line_tensor, hidden, ct)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Add parameters' gradients to their values, multiplied by learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 7GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:204"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "n_iters = 100000\n",
    "print_every = 1\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor, ct = randomTrainingExample()\n",
    "    output, hidden, loss = train(line_tensor, hidden, ct)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess = wordFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e4cef8edd8>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e4bc791390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    output = []\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-66f8c2527b79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "t = ' '\n",
    "line = ['T','h','e',' ']\n",
    "i = 0\n",
    "while t != '.':\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(sentence_to_tensor(line[i:1+4]))\n",
    "    t = charFromOutput(output)\n",
    "    line.append(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'o',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'o',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'o',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'o',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'o',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " ' ',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " ' ',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10906"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
