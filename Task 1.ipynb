{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from sklearn import svm\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)\n",
    "data = [d for d in parseData(\"train.json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = [d['reviewText'] for d in data]\n",
    "y = [d['categoryID'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [[] for d in range(5)]\n",
    "for d in data:\n",
    "    categories[d['categoryID']].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86423538, 119249800)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    f = open(gloveFile,'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "import gensim\n",
    "s= []\n",
    "for d in data:\n",
    "    r = ''.join([c.lower() for c in d['reviewText']])\n",
    "    sentences = r.split('.')\n",
    "    for sentence in sentences:\n",
    "        words = []\n",
    "        for w in sentence.split():\n",
    "            words.append(w)\n",
    "        s.append(words)\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "        s,\n",
    "        size=100,\n",
    "        window=10,\n",
    "        min_count=0)\n",
    "model.train(s, total_examples=len(s), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove = loadGloveModel('glove300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X[:100000])\n",
    "X_test = np.array(X[100000:])\n",
    "y_train = np.array(y[:100000])\n",
    "y_test = np.array(y[1000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_tensor(review):\n",
    "    punctuation = set(string.punctuation)\n",
    "    x = []\n",
    "    r = ''.join([c for c in review.lower() if not c in punctuation])\n",
    "    r = r.split()\n",
    "    for word in r:\n",
    "        if word not in glove:\n",
    "            r.remove(word)\n",
    "    tensor = torch.zeros(len(r), 1, 100)\n",
    "    for li, word in enumerate(r):\n",
    "        if word in model:\n",
    "            tensor[li][0] = torch.from_numpy(model[word])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "n_categories = 5\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(100, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2out = nn.Linear(hidden_dim, 5)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        lstm_out, self.hidden = self.lstm(input, self.hidden)\n",
    "        out = self.hidden2out(self.hidden)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "n_hidden = 100\n",
    "rnn = RNN(100, n_hidden, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    tensor = torch.zeros(1, 5)\n",
    "    tensor[0][category] = 1\n",
    "    return tensor\n",
    "\n",
    "input = review_to_tensor(reviews[3])\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "category = categoryTensor(y[3])\n",
    "output, next_hidden = rnn(input[0], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.5831,  4.2803, -4.4527,  ...,  0.7554, -0.4660, -2.0357]],\n",
       "\n",
       "        [[ 4.4599, -2.3481, -0.8871,  ...,  5.3055, -0.4463,  5.2171]],\n",
       "\n",
       "        [[ 4.8540,  3.0677, -0.8828,  ..., -3.0054,  0.3446, -1.2148]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3005, -3.7607,  1.5351,  ..., -3.4989, -1.5394,  1.2987]],\n",
       "\n",
       "        [[ 3.5993,  3.1479, -2.3967,  ...,  0.2867, -2.6979, -2.1864]],\n",
       "\n",
       "        [[-1.7778,  2.3472,  0.1473,  ...,  0.4434,  0.6594, -6.2985]]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_tensor(reviews[73959])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3889, -1.4541, -1.7246, -1.8057, -1.7461]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return category_i\n",
    "categoryFromOutput(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(line_tensor, hidden, ct):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, ct)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, hidden, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'I LOVE these beautiful earrings. I wanted something for that 2nd hole up higher on my ear lobe. I wanted something large enough to be seen and add a little color to my pale complexion. These are just what I wanted!',\n",
       " tensor([[1., 0., 0., 0., 0.]]),\n",
       " tensor([[[ 4.1525,  0.2597,  0.4140,  ..., -0.9523, -2.6033, -1.6936]],\n",
       " \n",
       "         [[-1.3386, -0.9493,  3.4099,  ..., -2.0856, -2.7873, -2.5723]],\n",
       " \n",
       "         [[-2.1854, -0.7062, -1.3682,  ..., -2.4345,  3.0724, -2.1045]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.3475, -1.5548, -1.2212,  ...,  3.4966, -2.6836, -1.3082]],\n",
       " \n",
       "         [[ 4.1525,  0.2597,  0.4140,  ..., -0.9523, -2.6033, -1.6936]],\n",
       " \n",
       "         [[ 2.5461, -0.7319,  0.5716,  ..., -1.2392, -1.3994,  0.9284]]]),\n",
       " tensor([0]))"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randomTrainingExample():\n",
    "    i = random.randint(0,len(reviews)-1)\n",
    "    category = y[i]\n",
    "    line = reviews[i]\n",
    "    line_tensor = review_to_tensor(reviews[i])\n",
    "    if len(line_tensor) == 0:\n",
    "        return randomTrainingExample()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    ct = torch.tensor([category], dtype=torch.long)\n",
    "    return category, line, category_tensor, line_tensor, ct\n",
    "randomTrainingExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (1m 6s) 0.3788 I have never worn crocs before, so I'm not sure I'm the best to review these.  They were very sloppy and oversized and I normally wear a size 9M. / 0 ✓\n",
      "10000 10% (2m 11s) 4.5784 The flower is larger (but not too large, like some of the baby satellite antennae available out there) than I thought it would be and is much much prettier.  I expected to like it but I love it.  Love it! / 0 ✗ (4)\n",
      "15000 15% (3m 15s) 0.2901 This is a very comfortable shoe. It has several cutouts that make it more like a sandal. The photo does not show al of the cutouts. It was only after I saw this shoe at a store that I realized how like a fisherman's sandal it was.  I guess Clark's is not using the Privo Brand so much now, but this is a Privo type shoe and has the little bumps in the insole like the Privos did.I was pleased to see how many colors are available and plan to order another pair. The only downside on some colors is that the elastic straps are not a perfect match for the leather. / 0 ✓\n",
      "20000 20% (4m 17s) 0.1653 GREAT-GREAT support!!! Very comfortable and VERY supportive (my bra size is 38C). I was amazed how supportuve it was when I wore first time. Not all bras with wires are so good. I bought it for wearing in the night.  I don't wear it during the day because ... I don't want to be embarrassed when it's cold.:-)  Other than that - it's a great bra!!!The only problem that I have had with it - the fabric has faded in the front (because of cosmetics with acid (for skin with acne) I apply on my chest before I go to bed) but it my fault.  Just want to warn people.  So make sure you apply cosmetics only on your chest, avoid contact with the fabric.Going to buy it again. And again. And again. / 0 ✓\n",
      "25000 25% (5m 20s) 1.3540 Very pleased with this watch. Even though not assembled in Switzerland, the inner components are all Swis made. I own very expensive watches, so I'm anxious to see how the Invicta product endures. / 0 ✗ (1)\n",
      "30000 30% (6m 23s) 2.0646 I ordered two of these. One black and one Khaki. Both are ok, but stand too tall even for an old style cap. The hook & loop sticks to everything. / 0 ✗ (1)\n",
      "35000 35% (7m 25s) 0.1284 this is not the watch that I ordered, it is more beautiful, I guess they were out of the one that was advertised and they substituted this one and I am glad they did, I love it / 0 ✓\n",
      "40000 40% (8m 27s) 0.1160 When you first put these on they are really nice but after a while they get pretty loose and move around which gets pretty annoying. The fabric is pretty light which makes it a bit more breathable but definitely not more durable. I really like the color too. / 0 ✓\n",
      "45000 45% (9m 28s) 0.5550 These are funky sneakers -  I bought them mostly because of the color - they're meant to be more like running barefoot and NOT recommended to wear all the time - that's the only drawback, but I have worn them for full days and have not noticed any issues in my legs or knees (they come with a warning about this) / 0 ✓\n",
      "50000 50% (10m 29s) 1.4700 My title pretty much says it all!  First, let me give you a bit of my background:  I own a manufacturing plant and from time to time (meaning several times a day) I am out on the production floor or in the machine shop or maintenance building.  The environment ranges from dusty to oily to dirty.  For years, I would wear khaki's, but after a day, wrinkles abound.  A couple of years ago, I switched to gabardine pants, purchased from JA Banks, Lands End and Brooks Brothers.  On a lark, while killing time in a mall while my wife and daughter were shopping, I came a across a pair of these pants in a color/fabric that I liked.  I tried a few pair on and ended up with a size that is a perfect fit (I normally wear a 36 waist with a 31 inseam).  That size is 38 waist and 30 inseam (so the pants run a tad small).  Long story short:  they wear like iron and look great for multiple wearings.  Hang them up and wrinkles seem to disappear!Since that first pair, through the passing months I have ordered at least 5 more pair.  All fit exactly like the first and all wear the same!  To be truthful, I never expected a pair of trousers of this caliber from Haggar, but these are simply a bargain at the roughly $35.00 price point.  Yes, I still wear Brooks Brothers and Polo/Ralph Lauren, but these are damn near as good at one-third the cost! / 0 ✗ (1)\n",
      "55000 55% (11m 30s) 0.1880 Attractive low heeled loafer, great for slacks.  The sizing is not true to fit.  I had to return these.  They ran a good half size too long, but I chose to not replace them with another size.  Sometimes that becomes an unending exchange sending back and forth to correctly fit.  I picked out a different Clarks shoe and it fit perfectly. / 0 ✓\n",
      "60000 60% (12m 29s) 0.1670 One star off for being a little longer than expected and fabric is thinner than what it looks. FIts great, I am in between the size S and M based on their measurements so I went with M. I am 5'3 and 140 lbs with 29&#34; waist and 37 hips. Looks elegant and fits comfortably. Nice stretchy material. If you buy lighter color, may need a slip under it. Will definitely buy another one. / 0 ✓\n",
      "65000 65% (13m 32s) 0.6241 I tried on at least 5 sets of fleece-lined tights from Amazon and these were by far my favorite. They are warm, but look just like normal dark tights. They do cling to wool more than normal tights, but work well under other fabrics or lined skirts. These fit as expected and they come up high enough (lots of the fleece-lined tights I tried sat too low). They are not tight on the top and do not create the dreaded &#34;muffin top.&#34; They are also good quality and seem like they will last a long time. (I have already worn and washed them three times and they seem just like brand new.) Several of the other fleece-lined tights I tried on were already damaged or tore when getting them out of the package -- these were the definite winners. / 0 ✓\n",
      "70000 70% (14m 33s) 0.2482 I love this ring because it is believable that i could actually afford a diamond ring like this one and no one would think twice. The ring shines and sparkle beautifully. I've received more compliments than i anticipated. This ring is believable for the average working couple who's on a budget. Let's be real most of us on Amazon looking for a nice deal for our buck well this ring you can't go wrong for the price and on Amazon an upgrade is ssoooo easy to do when we're ready. Just think at these prices an upgrade can be done yearly. If you like change like i do this is an ideal way to purchase wedding rings. Spending 800-1000 on rings you stuck with the same look for years the average working Joe I'm speaking of. That same money i can change up at anytime and not feel guilty about money. The rings are beautiful and came so fast. / 0 ✓\n",
      "75000 75% (15m 36s) 0.5651 These are quite beautiful and perfect gifts for granddaughters who need to know their Guardian Angels are always with them. / 0 ✓\n",
      "80000 80% (16m 40s) 0.9715 It is very nice but way too long.  My husband is 5'11 1/2.  It dragged on the floor and then some. / 1 ✓\n",
      "85000 85% (17m 42s) 1.9275 These shorts are as described, but I didn't read closely enough to make sure they had pockets, which they don't.I like them otherwise, so I kept them. But since I always have doggy bags and licorice in my pockets, I find that I just don'twear them. They are good quality and nice length and color. But I'll probably will end up donating them to a thrift store. / 0 ✗ (1)\n",
      "90000 90% (18m 42s) 0.0795 I love Aerosoles, but the shaft was to high for me. I am 5'4, and the boot came all the way up to the back of my knee. I could feel the boot every time I bent my knee. It was not comfortable. I sent them back. If you have long legs, the boots would be great. I have short legs. / 0 ✓\n",
      "95000 95% (19m 45s) 0.2381 I wasn't sure what to expect when ordering this... however, I was quite suprised at the quaility and fit. The fit of this bra is good around my chest moreover, the fit of the cup for my size (B-C) is perfect for me. My breasts land perfectly in the cups and achieve the look I'm going for.  The fabric is smooth and not scratchy.  It washes well and is beautiful on.  With that said, MY HUSBAND LOVES IT JUST AS MUCH!!!  And for the amount of time it stays on me and the reaction I get, it&#8217;s achieving what I intended it to do! / 0 ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100% (20m 47s) 0.7103 Very good quality, very nice fit.  Reviews that other buyers posted were very helpful.  In fact, the reviews are what I go by, not just the product description.  They tell you pretty much everything you need to know, and there are no surprises. / 0 ✓\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor, ct = randomTrainingExample()\n",
    "    output, hidden, loss = train(line_tensor, hidden, ct)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13026c5f048>]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd0XNW1+PHvnqbeJUuyum254yoX\nMAQTSmxCCSUEB9IgjySQ3pOXFfIjLz15yUtIIIQQhxIIHUPo3QbbWO69yrIlWd2WZPWZOb8/pliy\nRtLYGlme0f6s5YVm7tWdM75mz5l99jlHjDEopZSKLJaRboBSSqnQ0+CulFIRSIO7UkpFIA3uSikV\ngTS4K6VUBNLgrpRSEUiDu1JKRSAN7kopFYE0uCulVASyjdQLp6enm8LCwpF6eaWUCkvr16+vN8Zk\nDHbeoMFdRB4ArgBqjTHTAxxfDDwHlHmfetoYc9dg1y0sLKS0tHSw05RSSvUgIuXBnBdMz305cDfw\n4ADnrDTGXBHMCyqllBp+g+bcjTHvAo1noC1KKaVCJFQDqueKyGYReUlEpoXomkoppU5TKAZUNwAF\nxpjjInI58CxQHOhEEbkNuA0gPz8/BC+tlFIqkCH33I0xzcaY496fXwTsIpLez7n3GWNKjDElGRmD\nDvYqpZQ6TUMO7iKSJSLi/Xm+95oNQ72uUkqp0xdMKeSjwGIgXUQqgDsBO4Ax5l7geuBLIuIE2oEb\njW7vpJRSI2rQ4G6MWTbI8bvxlEqeEburW3h+cxWfW1RIWnzUmXpZpZQKK2G3/MCBuuPc/dY+als6\nR7opSil11gq74B7tsALQ1uUa4ZYopdTZK+yCe6zdE9zbNbgrpVS/wi+4OzzDBO3dGtyVUqo/YRfc\nY/xpGecIt0Qppc5eYRfcYx2allFKqcGEXXCPseuAqlJKDSb8gruv5645d6WU6lfYBfcomwWLaFpG\nKaUGEnbBXUSIddg0LaOUUgMIu+AOntRMe7dWyyilVH/CM7jbrdpzV0qpAYRlcI91aHBXSqmBhGVw\nj3FY6dBqGaWU6ldYBnftuSul1MDCMrhrzl0ppQY2aHAXkQdEpFZEtg1y3jwRcYnI9aFrXmAxDhvt\nuraMUkr1K5ie+3JgyUAniIgV+BXwSgjaNKhYu1VnqCql1AAGDe7GmHeBxkFO+wrwFFAbikYNJkZz\n7kopNaAh59xFJAe4Brg3iHNvE5FSESmtq6s77deMdVh1+QGllBpAKAZU/wB8zxgzaLQ1xtxnjCkx\nxpRkZGSc9gvG2K043YYup/u0r6GUUpHMFoJrlACPiQhAOnC5iDiNMc+G4NoBxfRY091hC8uCH6WU\nGlZDDu7GmCLfzyKyHHhhOAM79N5qLwn7cL6UUkqFpUGDu4g8CiwG0kWkArgTPBHVGDNonn04xOpW\ne0opNaBBg7sxZlmwFzPGfHZIrQnSiX1UdVBVKaUCCcuEtW+rPa11V0qpwMIyuMdqz10ppQYUlsG9\nZ7WMUkqpvsIyuJ+oltEBVaWUCiRMg7umZZRSaiBhGdyj7ZqWUUqpgYRlcI/VnLtSSg0oLIO73WrB\nbhXatBRSKaUCCsvgDp5ad+25K6VUYGEb3GMdNl1+QCml+hG2wV037FBKqf6Fb3C3W+nQnLtSSgUU\ntsE9VnvuSinVr7AN7pqWUUqp/oVvcNdqGaWU6tegwV1EHhCRWhHZ1s/xq0Vki4hs8m5+fX7om9lX\nrMOqS/4qpVQ/gum5LweWDHD8DWCmMWYWcAtwfwjaNagYh03TMkop1Y9Bg7sx5l2gcYDjx40xxvsw\nDjD9nRtKsQ4r7VrnrpRSAYUk5y4i14jILuA/eHrv/Z13mzd1U1pXVzek14x1WGnrdnHic0UppZRP\nSIK7MeYZY8xk4GPATwc47z5jTIkxpiQjI2NIrxltt2IMdDrdQ7qOUkpFopBWy3hTOONFJD2U1w1E\nV4ZUSqn+DTm4i8gEERHvz3MAB9Aw1OsOxr9hh1bMKKVUH7bBThCRR4HFQLqIVAB3AnYAY8y9wHXA\np0WkG2gHPmHOQCI8xrfVng6qKqVUH4MGd2PMskGO/wr4VchaFKRYu261p5RS/QnfGaq6j6pSSvUr\n7IO7zlJVSqm+wja4a7WMUkr1L3yDu90zXKBpGaWU6itsg7s/LaPVMkop1Uf4B3fNuSulVB/hG9y1\nFFIppfoVtsHdahGibBYdUFVKqQDCNriD7qOqlFL9CfPgrht2KKVUIGEd3KPtFjp0QFUppfoI6+Du\n6blrKaRSSp0srIN7jObclVIqoLAO7rEOq9a5K6VUAGEf3LXnrpRSfQ0a3EXkARGpFZFt/Ry/SUS2\neP+8LyIzQ9/MwKLtVq1zV0qpAILpuS8HlgxwvAy40BgzA8/m2PeFoF1B0bSMUkoFFsxOTO+KSOEA\nx9/v8XANkDv0ZgVHq2WUUiqwUOfcbwVeCvE1+xVjt9LR7cbtHvYtW5VSKqwM2nMPlohchCe4nz/A\nObcBtwHk5+cP+TV9K0N2OF3EOkL2VpRSKuyFpOcuIjOA+4GrjTEN/Z1njLnPGFNijCnJyMgY8uvG\n6j6qSikV0JCDu4jkA08DnzLG7Bl6k4LnW/ZXK2aUUqq3QXMZIvIosBhIF5EK4E7ADmCMuRf4MZAG\n/EVEAJzGmJLhanBPvlSM9tyVUqq3YKpllg1y/PPA50PWolNwIi2jFTNKKdVTWM9QjY/2fDY1d2hw\nV0qpnsI6uGcmRANQ29wxwi1RSqmzS1gH9zGJUQDUaHBXSqlewjq4R9utJMfaqWnuHOmmKKXUWSWs\ngzt4UjPac1dKqd7CPriPSYyipkV77kop1VPYB/esxGhqmrTnrpRSPYV9cM9MjKbueCcuXTxMKaX8\nIiC4R+FyGxpaNTWjlFI+YR/cxyT6at01uCullE/YB/csb3Cv1ry7Ukr5hX1wz/QG95oWDe5KKeUT\n9sE9Pd6BCDqRSSmlegj74G6zWkiPj9JySKWU6iHsgzt4a901LaOUUn6DBncReUBEakVkWz/HJ4vI\nahHpFJFvh76Jg8tMjNK0jFJK9RBMz305sGSA443AV4HfhqJBp2NMYrQu+6uUUj0MGtyNMe/iCeD9\nHa81xqwDukPZsFORmRBNQ2sXnU7dbk8ppSBScu5JnnXd63QBMaWUAs5wcBeR20SkVERK6+rqQnZd\n3yxVzbsrpZTHGQ3uxpj7jDElxpiSjIyMkF1Xt9tTSqneIiItk+ndbq9ag7tSSgFgG+wEEXkUWAyk\ni0gFcCdgBzDG3CsiWUApkAi4ReTrwFRjTPOwtfokqXEO7FbRtIxSSnkNGtyNMcsGOV4N5IasRadB\nRBiToOWQSinlExFpGfBOZNJZqkopBURUcI/WZX+VUsorooK7btihlFIeERXcWzqdtHY6R7opSik1\n4iIouHvKIWt1lqpSSkVScNft9pRSyidignteSiwAZfWtI9wSpZQaeZET3FNjSI61s6Xi2Eg3RSml\nRlzEBHcR4ZycJDZXNI10U5RSasRFTHAHmJmbzJ6aFtq7dF13pdToFlHBfUZuEi63YccR7b0rpUa3\niAruM/OSAdh8WIO7Ump0i6jgnpkYTWZiFJt1UFUpNcpFVHAHmJGbzBYdVFVKjXIRF9xn5SVTVt9K\nU/uI7detlFIjLuKC+4zcJAC2au9dKTWKDRrcReQBEakVkW39HBcR+aOI7BORLSIyJ/TNDN6MHO+g\nqubdlVKjWDA99+XAkgGOLwWKvX9uA+4ZerNOX1KsncK0WJ2pqpQa1QYN7saYd4HGAU65GnjQeKwB\nkkUkO1QNPB06qKqUGu1CkXPPAQ73eFzhfa4PEblNREpFpLSuri4ELx3YjNwkjjR16J6qSqlRKxTB\nXQI8ZwKdaIy5zxhTYowpycjICMFLB+abzLTpsKZmlFKjUyiCewWQ1+NxLlAVguuetnNykohzWHlz\nV+1INkMppUZMKIL7CuDT3qqZhUCTMeZICK572qLtVi6blsVL26rpcrpHsilKKTUigimFfBRYDUwS\nkQoRuVVEvigiX/Se8iJwANgH/A24fdhaewqunJlNU3s3K/cOX25fKaXOVrbBTjDGLBvkuAHuCFmL\nQuT8CRkkx9p5fnMVF0/JHOnmKKXUGRVxM1R9HDYLS6dn8eqOGl3fXSk16kRscAe4cuZY2rpcOrCq\nlBp1Ijq4LyhKY0xCFCs2V450U5RS6oyK6OButQgfnZHNW7vraO7QVSKVUqNHRAd38KRmupxuXtte\nM9JNUUqpMybig/vsvGTS46NYta9+pJuilFJnTMQHdxFh4bhU1hxowFO1qZRSkS/igzvAwnFpHGnq\n4FBj20g3RSmlzohRE9wB1hxoGOGWKKXUmTEqgvv4jDjS46NYc2CgZemVUipyjIrgrnl3pdRoMyqC\nO2jeXSk1uoyq4A6ad1dKjQ6jJrhr3l0pNZqMmuCueXel1GgSVHAXkSUisltE9onI9wMcLxCRN0Rk\ni4i8LSK5oW/q0GneXSk1WgSzE5MV+DOwFJgKLBORqSed9lvgQWPMDOAu4Behbmgo+PLub+kSwEqp\nCBdMz30+sM8Yc8AY0wU8Blx90jlTgTe8P78V4PhZYXxGHFOzE7nrhR38/rU9OF26v6pSKjIFE9xz\ngMM9Hld4n+tpM3Cd9+drgAQRSRt680JLRHj8i+fysdk5/N8be/nEfWuoOtY+0s1SSqmQCya4S4Dn\nTh6R/DZwoYhsBC4EKgFnnwuJ3CYipSJSWlc3MhtXx0fZ+N8bZvF/N85id3ULX3l0ow6wKqUiTjDB\nvQLI6/E4F6jqeYIxpsoYc60xZjbw397nmk6+kDHmPmNMiTGmJCMjYwjNHrqrZ+Xww8unsL78KK/u\n0LXelVKRJZjgvg4oFpEiEXEANwIrep4gIuki4rvWD4AHQtvM4XFDSS7jM+L49cu7NP+ulIoogwZ3\nY4wT+DLwCrATeNwYs11E7hKRq7ynLQZ2i8geIBP42TC1N6RsVgvfXTKZ/XWtPLG+IuA5aw408Nwm\n3YP1bGWM4blNlbR19ckCKjWqBVXnbox50Rgz0Rgz3hjzM+9zPzbGrPD+/KQxpth7zueNMZ3D2ehQ\numxqJnMLUvj9a3sCBoj/+c8Ovv3EZip14PWstKfmOF97bBPPbqwa/GSlRpFRM0O1PyLCDy+fTG1L\nJ/9472CvY9VNHWyrbKbbZbjvnf0hfd29NS243TqQO1T7644DUN7QOsItUersMuqDO8DcglQ+NDGD\nh9eU4+oRcN/0TnaaV5jCo+sOU9vScUrXrWvp5M7nttHa2fsbwf6641z2h3d5aVv10Bs/ypXVe4J6\neYPOOlaqJw3uXh+fm8uRpo5eq0a+uauG3JQYfnP9TJwuN/evLDulaz7wXhn/XF3OO3t6l32WHmzE\nGNhXezwkbR/NDtR5g7suKaFULxrcvS6dmklClI2nN3gGTzu6XazaV8/Fk8dQmB7HVTPH8vCachpb\nu4K6XpfTzePrPHO/1pcf7XVs46FjABw+OrIBqbG1i3vf2U93GFcKldV7PiAPNbTqfAWletDg7hVt\nt3L5Odm8tO0IbV1OVu9voKPbzcVTMgG446IJtHe7+Md7wfXeX95eTUNrFwnRNkr7Ce4VIxzcf/Ts\nVn750i7e3j0yE8pCoay+FbtVaO1y0RDkB69So4EG9x6unZNDW5eLV7ZX88auGmIdVhaMSwWgODOB\npdOzeGBVWVBLFjyyppy81Bg+uSCf7ZVNdHS7AGjp6GZPbQsAFUdHrgLntR01vLi12vtzeOb+j7Z2\ncbStm5ICzz3S1T6VOkGDew/zClPJTYnh6Q2VvLmzlguK04myWf3Hf7B0Cm4DP35u24ApgH21Lawt\na+ST8wuYV5CK023YfNjTW99S0YQxMDM3iSNNHUFPnvrB01u4f+WBob1Br+OdTn783DYmeT+w3thZ\n22sgOVyUeStkFk/yzHY+pIOqSvlpcO/BYhGumZ3Dyr31VDV1cPHkzF7H81Jj+ealE3l9Z62/1xvI\nw2sOYbcKN5TkMqcgBYD1hzypmY3e/14xYywut+FI0+AVOB3dLp4oreBfHxw63bfWy29f2U11cwe/\nvO4clkzPoqG1i03eD59wUuYdTL2gOAMRrZhRqicN7ie5ZvaJBS8vmjymz/HPLSrknJwk7lyxnaa2\n7j7H27tcPLWhgqXTs0mLjyI1zsG4jDg2lPuC+zEmjIln6thEILjUzLbKJpxuw4G6VmqaT60c82Rb\nK5r45+qDfObcQmbnp7B44hhsFuH1nb3X1zm5fDMU3ttXz1P9zAQ+HWX1rVgtwoQx8WQlRlPeqLXu\nSvlocD/JuIx45hemMq8whYyEqD7HbVYLv7zuHI62dfHzF3f2Of785ipaOpzctCDf/9zc/BTWlx/F\n7TZsOnyM2XnJ5KbEAMFVzGw4dGJAdqgbfL+6oxqLCN+8bCIASbF25hel8nqPxdPe21fPrLte5Y9v\n7B3Sa53sd6/u5ifPbw/Z5K2y+lbyUmJw2Czkp8ZqWkapHjS4B/C3z5Rw/2fm9Xt82tgkbllUyL9L\nD/epVX94bTkTM+OZX5Tqf25uQQpH27p5Z28dDa1dzM5PITspBosE13PfeOgYOckxJETb+gT3o61d\n1J5Cb35rZRPFY+JJjLb7n7t0aiZ7a49zsL6V451OvvvkFgD+97U9PBaiVFBbl5MtFU20dDgHrEnv\n6Haxen8DnU7XoNc8UN9KUXocAAVpsVrrrlQPGtwDSIqxkxRjH/CcL1w4niibhb+vOjHIufnwMbZU\nNHHzwgJETiyDX1Loybv7BkRn5yfjsFnISowetBzSGMOGQ0cpKUxhQVEqq/f3Du5feGg9tz20Pqj3\nZYxhW2UT03OSej1/ibfc8/WdNfzqpV1UNbXz0K0LuHBiBj98ZiuvhWBJ5I2HjuH09ti3VvZZDdrv\n4TXlLPvbGs79xZv89IUd7PNWFp3M7TYcrG+lKD0egIK0OOpaOmnvGvxDQanRQIP7aUqPj+K6ubk8\ntaGSuhbPOmkPrSkn1mHtlbcHGJceT1KMnff2NRDrsDIxMwGA3JRYKhoH7rkfaeqgprmTOfkpLByX\nxsGGNo40eX5n55FmPjjYyN6alqAm8FQ3d1B/vItzTgrueamxTM5K4IFVZTy0ppxbFhWxcFwaf7lp\nDufkJPHlf23g/f31fa53rK0r6AlQa8sasQg4rBa2VvQ/eLu5oon0eAcLx6Xy4OqDfPSPqwJ+ANa0\ndNDe7aIow9Nzz0+NBfovhyxvaKWpve8YiVKRSoP7EHz+/CK6XW7++f5BjrV18fzmKq6ZnUNCdO9e\nv8UizPVWzczMTcZq8fTqc1NjBu25+/Lts/OT/Rt8+1Iz/1rrSZm0drmCmjm7tcLTYz655w6e1ExV\nUweFabF8+7JJAMRF2Xjgs/MoSIvlsw+s4z9bjgCebwB/X1XG/J+9wR9e3zPo6wKsPdDA9Jwkpo5N\nZEtF/z337VVNzMlP4S83zeWZ2xfR6XTz/v6+4wy+Splx6b2De6AFxNq6nFzxp1X8+uVdQbVVqUig\nwX0IxmXEc+mUTB5aU86Dq8vpdLq5eWFBwHN9wX12frL/udyUWKqbO+hy9t/73XjoGFE2C1OyE5ma\nnUhSjJ3V+xto7XTyzMZKshKjgeDWVtla2YRFYGp2Yp9jV80cS0ZCFL/5+ExiHCdq+9Pio3j8C+cy\nMy+JLz+6gXve3s8ty9fx0xd2gBBUyqbT6WLj4WPML0xlRm4S2yqbAg6qtnU5Katv9VcSTRubSGqc\ngw/KGvuce8C7YFjPnDsE7rm/uLWalg5nWJZ7KnW6ggruIrJERHaLyD4R+X6A4/ki8paIbBSRLSJy\neeibenb6woXjaGrv5g+v72FeYQpTAgROwN/r7jnQmpsSg9vgT7MAvLztSK8ZsBsOHWVGbhJ2qwWL\nRTx59wMNPLepiuOdTr55qafq5XCQwb14TEKv4O1TnJnAuv++hHmFqX2OJcc6eOjWBVwyJZNfvbyL\n9/Y3cNfV0/jGJRPZU3N80PLMzYeb6HK6mV+UyvScJFq7XP7g3NOu6haM8QxYg2c55nmFKQGDe1l9\nK9F2i//DLTnWQWK0LWCt++OlnjV+9tYcH/CDVKlIMmhwFxEr8GdgKTAVWCYiU0867Ud4dmiajWcb\nvr+EuqFnq7kFqcwtSMFt6LfX7jkvhZe/fgEXTjyxd2xeiqe36auYqTrWzhcf3sBtD5XS7XLT6XSx\nvbKZOfkp/t9ZOC6Nw43t/PmtfUzJTuSqWWOBvhN4Glu72NZj4NI3mHpObt+UTDCi7VbuuWkOd109\njRVfXsSnzy3kguJ0wFM6OZAPyjxplflFnp470KttPturmgH8PXfwzBo+1NhG9UmTvcrqWylMi8Ni\nOTFwXZAW1+cbTFl9Kx+UNTI1O5Eul1tX4lSjRjA99/nAPmPMAWNMF/AYcPVJ5xjA939kEidtoB3p\nvr90MkunZ7FketaA503OSuxVReOvdfcGpFe2e2a9bqts5u4397Gjqpkul7tXKufc8Z5vAJXH2rlp\nQT7RditZidF90hF/fGMv1/zlPX+ZZH+DqafCZrXw6XMLmZzludVTsz1pk1V7Bw7ua8samZyVQHKs\ngwkZ8UTbLQHz7juqmkmKsTM2Kdr/3IIiz/v94GDv3ntZfSvjvIOpPvlpsX2+wTy5/jAWgf/+6BTP\naxxpDvLdho/9dcd5WfcGUCcJJrjnAId7PK7wPtfTT4CbRaQCeBH4SkhaFybmFaZyz81ze61DE4zs\npGisFvH33F/aVs2kzASumZ3D3W/t48HV5QDM7tFzn5SZQEqsnTiHlY95q3ICTeDZVtlEt8vw8BrP\nNQYaTD1dFotw3vg0Vu2r77dap9vlZn35UX86yma1MG1sElsr++a/dxxpZtrY3h+AU7ITiI+y+Xv/\nvmseamzz59t9ClJjqTja5l8nx+ly8+T6ChZPGsPCcWlE2y1sr+r9odLc0U1LR98qmrd21XLvILtv\nlTe08pMV20d8yeQ/v7mPrzy6wb84nVIQXHCXAM+d/H/yMmC5MSYXuBx4SET6XFtEbhORUhEprasL\n32VmQ8VmtZCd5Kl1r2vpZN3BRj4yPYufXDWNjPgontlYSU5yDJmJJ3qyFovwtYuL+f7lU4iPsgGe\nHmvPnrvbbdhV7akPf2TtITq6XWwbYDB1KC4oTqe2pZO9/aQ7tlc109bl8vfAAc7JSWJbZXOvxcqc\nLje7jjT3aZ/NamFOQQrryk7M0j1Y34rLbfw17j4FabF0u4x/zGLl3npqmju5oSQPq0WYnJXIjqre\nPffPLy/l0w980OvDyeU2/HjFNn718q4BxzL+tvIAy98/6F/CeaTsqW2h22Ui8luJOn3BBPcKIK/H\n41z6pl1uBR4HMMasBqKB9JMvZIy5zxhTYowpycjIOPnwqJSbEsPho+28tqMGY2Dp9CySYuz8+voZ\nAMzqkZLx+eyiIj7VI7+fn+qpuvH13CqPtXO808kVM7JpaO1ixeYqtgwwmDoU5xd77uPKflIza71l\nm/OKTnz7mJGbRHu3y7//KXjSLJ1Od698u8+ColR217Rw1Fvu+dd3D+CwWlhQ1HvwN89bDrm/zjPb\n9p+rD5IW5+DD3jWCpo1NZMeRZn8gr23u4IODjWw8dIw1B06kfd7eXcvhxnaMgSf6WQvH6XL7F4/r\n+a3iTHO7jX8cYbNWA6keggnu64BiESkSEQeeAdMVJ51zCLgYQESm4Anu2jUPQm6KJ5Xw0rYjFKZ5\nJhMBfGhiBnd/cjbfuKR40Gv4ygB9NfO+Htyt5xf5JycFmpkaCjnJMRSlx7Fqb+Db/d7+BsalxzEm\n4cS3D9+g6tYeeXdfm32VMj35UjrrDjaytaKJJ9dX8LnzC/3B3KcgzZOm+ew/1rH4t2/z9u46bpyf\nh8Pm+Wc+dWwiLR1OfxrsDe8euTF2K/e9eyIFs/z9g2QmRnHe+DSeLD0ccDnk9/c30Njahc0ifHCw\n92Ys1U0dfPJva4KqYBqqiqPtdHR70kJa6ql6GjS4G2OcwJeBV4CdeKpitovIXSJylfe0bwH/JSKb\ngUeBzxrd8ywoeSmx1DR3snp/A0umZ/fKN18xYywTxiQMfg3/BB5PMNl5pBkRmJSVwC2LithV3eId\nTA1tSsbn/AnprC1r7FNmWHWsnVV761h6Tu+B5qL0eGId1l7LEGyvasZhs/QZJAXPh4HDZuGDskb+\n3/PbSY938OWLJvQ5b2xSNN/5yCS+enExv7l+Bv++bSHfunSS/7jvg8OXd399h2eP3C9eOJ63dtex\np6aF/XXHWbm3npsXFHDTggKqmjpYGeCD6/nNVSRE2bh2Tg7rDzb2Wpf/2U2VvL+/gb+vOrU9d0/H\nnhpP+i0rMVqDu+olqDp3Y8yLxpiJxpjxxpifeZ/7sTFmhffnHcaYRcaYmcaYWcaYV4ez0ZHEVzHj\ndJtBq236U3DS1PtdR1ooTIsj1mHjqlljSY1zAJx2GeRgzi9Op63L5V+r3ufx0sO4Ddw4L7/X81aL\nMH1sEpt7LEOwo6qZSZkJ2K19/0lG2azMykvmXx8corT8KN+6bFKfWcDgqYu/46IJfPPSiXy8JI8F\n49J6lUpOzkrAIp7Xau/y7JF7yZRMPnVuAdF2C3979wAPvn8Qh9XCjfPzuWTqGFLjHP46eZ9Op4uX\nt1dz2bQszi/OoLXLxc4jJ9bA8U3semp9BW1dp7508nee2Bz0B4NvrOPaOTmUN7T5U1c+g9X1dzpd\n/PaV3TQc7zzldqqzm85QHWG+4D42KZqZpxl8U+McxDmsJ3ru1c1Myfb0+KPtVj53XiEJUbZ+J1gN\n1cJxaVgE3uqxF6vLbXh83WEuKE7vkz4BOG9CGhsPHePx0sMYY/yVMv1ZUJRKW5eLKdmJ3FCS1+95\nA4m2WxmfEc/2qmZW7aun0+nmkimZpMY5uKEkj2c3VfLk+go+OiObjIQoomyedYJe21HTK/i9u6ee\nlg4nV87MZr530tdab969rqWTDYeOcuHEDFo6nTy36dSqgju6XTy9sZI/vbk3qOqXvTUtZCVGc4F3\n7GNTjw/MJ0oPM/enr1E/QOBec6CRu9/axx9eD+3yzmrkaXAfYfnefPlHpmf1SsmcChEhPy2Ow41t\ntHY6KW9o89eig2dz75Xfu4hze4xKAAAWhklEQVRYhy0kbT5ZUoydS6Zk8o/3yvyDe+/uqaOqqYNl\n8/MD/s7tiydwQXE6P3h6K4+sPURja1fAwVSfxZPGYLcKd1451b82z+nwDaq+vqOGhCibP59/6/lF\nuNyG1i4Xnzmv0H/+J+bl0e0yPLOx0v/c85urSIm1s2hCOllJ0eSnxvpn0b6x0zMw/r0lk5mSnchD\nq8uDWtTNZ+cRTxXRsbZu/1o+A9lbe5zizHhm5CZhEdjUo3Jn+fsHael08uLW/q+zx1tV9di6Q1QG\nsTewCh8a3EdYdlIMv7z2HL60ePyQrpOfGkN5Y5u/BLJnL91iEZJjHUO6/mD+52PTiXVY+ebjm+h2\nufnXB4dIj3f4lxM+mcNm4d6b5zJtbCI/enYbwIA997kFKWz9yUf8yzicrqljEznS1MGL245w4aQM\n/2BrQVoc18/N5YLidGblnahQmpiZwOz8ZP6+qozHPjhE1TFPZdPSc7L9KaT5RamsO9iIMYbXdtSQ\nkxzDlOwEPrWwgB1HmtlwCqWSvpm76fFRPLK2fMBzfZUyxWMSiIuyUTwmwZ/q2lbZxPYqz9jLigG+\nPeyqbiEh2oYg3P3m2dN71yG7odPgfha4cX5+r2qS01GQFsehxjZ/1YkvLXOmjEmM5ufXnMOWiibu\nXLGdN3fVcv3cE5UqgfhWnSxKj8MiMClr4LRRtH3oZZy+QdWWDmefD55fXz+Th25d0Od3vr9kMg6b\nhe8/vZXzfvkm7d0urpwx1n98fmEqR9u62VLRxMp99Vw2LRMR4epZY0mIsvknkgVja2UTKbF2vrR4\nPBsOHetTl99TxdF22rtdTMz01PvPyktm8+FjGGN4vPQwDpuF/7pgHKXlR/tdfXRPTQuz8pJZNj+P\nJ0orzordrFbvb2Dana9wMMD6Qyp4GtwjRH5qLF1ON+/sriMh2kZOcswZb8PSc7K5dnYO/1p7CJfb\ncOO8wXPj6fFR/Pu2hfzjc/P9k7KGk2+SlNUiLJ4U3FyLBePSePvbi3nhK+fzpcXjuXFeXq8F4Hw/\n//bV3XQ53Vw61fOhERdl47q5ufxny5Ggd8vaWtnM9Jwkrp+TS7TdwsMD9N73ejcyKfYG95l5yRxt\n62ZPzXGe3VjJkmlZ/vkQz2/um5pxuQ17a1uYmJnA7RdNwGoR/ngW9N4fWnOQti5Xn319zzSny01t\ny9D2LB5JGtwjhG8985V765hy0ho2Z9JPrp5GbkoMiydlUJjet6wxkDGJ0b0WVBtOKXEOclNimFeY\nckqpKhFhek4S31symV9eN6NX3r8gLZYxCVGs3FtPUozdP8gK8KlzPcH1qrvf86/BY4zh5W3V3Hz/\n2l5llh3dLvbWtDA9J4mkWDtXzhjLsxsrAy6PALCnxjO+4SuX9aWTfv3yLpo7nHxiXh55qbHMzk9m\nxea+qZnDjW10dLuZlJlAZmI0Ny8s4OkNFZSNYI/5WFsXr+/wzD9YNciCdMPtN6/u5qLfvD0sm8Wf\nCRrcI4RvIlOn083kM5yS6Skx2s6r3/gQ9948d8TaMJj7PlXCb66fGbLriQjzvL33iyePwdajnHN8\nRjxPfek84qNt3Pz3tXznic189I+r+OLD61m1r577V54oedxd3YLTbfyLu928sIC2LheP9rOP7d7a\nFjITo/xbQk7MjCfGbuWNXbXkpsRwrnd84qqZY9l5pJm9Nb23LPSNz0zyTpz7woXjsIic9r659688\nwC9e3DmktXae33KELpebkoIU1h5oDGov3eHQ2NrFg++X09rl6rNoXbjQ4B4hxibH+HuTw1XyGKxY\nhy0k+fHhMnVsYsDyzKHwLYXgS8n0dE5uEi985Xw+t6iQJ7y177/7+ExuPb+I9/fX+7f/803q8gX3\nGblJzCtM4ecv7uL6e97nle3VvWbL7q057t+yETzr8Ph+9+Nz8/w1/h+dkY1F6NN7902A8qV1xiRE\n86GJGazYXBVwM5WBdLvc/N/re/nruwe47cHS06rvB8/cgEmZCdz2oXG0d7vYUD4yE7P+8V4Z7d0u\nbBbps29xuNDgHiHsVgtjkz2DsiMd3Eejj83O4btLJnFxP9VB0XYrd145jfU/uoTXv3kh183N5YoZ\n2XS7DG94c8vbKptIirH75z6ICMs/N5+fXDmV6uYOvvDQem66fw1dTnevSpme5hSkYBG4viTX/9yY\nhGjOG5/Oc5uqelWh7K5pIT81tleJ7NWzxnKkqYN1p9hbXVfWSEunk6tmjuWdPXUsu28NH5Q1cv/K\nA9y6fB0/enbroNfYV3ucTYePcf3cXBaOT8NqEVbtO/OrmDR3dLP8/YMsmZbF3IKUgPsHhwMN7hEk\nPzUWEfzVE+rMSYy2c/viCQNWB4Fn20Jf2mZmbjLZSdH+Bci2VTVxTk5Sr/GSuCgbn11UxNvfXsz/\nu2oaaw408vMXd1J5zFMpU3zSvf7S4vE89aXz+gyoXzVrLIca29jYY4mCPdUt/pSMz6VTM4mxW3ku\nQI5+IG/sqsVhs/CLa8/hr58qYVd1Czf8dTX/85+dfFDWyCNrDw26QflTGyqwWoSrZ48lMdrOrLzk\nQfcKAM+3hp+s2E5piNInD60up6XDyR0XTWDRhHS2VzVzrG3wPYrPNhrcI8h549M5f0L6sE1WUqFl\nsQhLpmfx7t46jrZ2sbu6hWn9rP9js1r4zHmF3LKoiOXvH+R3r+4G+n6QJ8XYe63/77N0ehZRNgvP\nbPBMxup0erY6nJTZO7jHOmxcNi2TF7ce6bV0waGGtn7z38Z4vn2cOy6NuCgbl07N5IWvnM+fls1m\nzQ8u5q+fnosxJzZ7D8TlNjyzoZIPFaf7y4IvKE5nS2XToIH1/pVlLH//IN96YvOQc/TtXS4eWFXG\nhRMzOCc3ifPGp2HMiU3pwbMw3C9e2jli4wHB0uAeQe64aELAOm119lo6PZsup5t739lPt8sMulPW\nDy6fzPzCVJ71TkwKZmE5gIRoO5dOzeT5LVV0Od0cqPOsiT8xq+/vXz1rLMfauv2VPG/tquWi373N\nr1/eHfDaB+pbOdjQxiVTxvifK85M4MqZY8lKimZWXjJWi7D+YP/B/b199VQ3d3Dd3BPppAuK0zHG\nswJnf8obWvnD63uYlJlAeUMb/3jv4GB/FQN6Yv1hGlq7+PKHPQvTzchNJtZh7dWG37yym7++c4C1\nB87ugVYN7kqNoLkFKaTHR7H8/YMAgwZ3u9XC3TfNZkxCFNlJ0f5KmWBcOyeHY23dvL271j+YOjlA\ncL+gOIOUWDvPbapi0+Fj3P7IBlxuw3+2HAk40OobM7ho8pg+x8DzbWD62MQB8/h/X1XWZ0bzzNxk\nEqJsAVflBM83hh8+sxWH1cKDt87n4sljuPvNfdS1nFhLZ/X+hlNaevmtXbVMGBPv3yjeYbMwvyjV\nv0/woYY2nt3k+fZzquMSZ5oGd6VGkNUiLJmeSafTTWK0zT9fYSBjEqL59xfO5e5Pzjml17qgOIP0\neAdPb6hkV3ULdqtQmNZ3LoLdauHyc7J5bUcNtyxfR3qCgx9ePpnq5o5eK3n6vLGzlslZCeSm9N/2\nksJUNh0+FnCVyh1Vzbyzp47PLSrqVWVls1pYOD6NlXsDb+P41IZK3tvXwPeWTiYzMZr//ugUOp0u\nfveqZ5XLOx7ZwLK/reGuF3YE9ffjdhs2HDpGSUHvtNZ549PYX9dKTXMH97yzD6sI+amxGtyVUgNb\nOj0b8OxvG+zks6L0OOYW9M2tD8RutXDlzLG8uauWdWWNjEuP73cA+OpZObR7V6V88JYFfGJePjaL\n8PL23htxN7V1U1p+tN81hHzmFabQ6XSzrarvxuj3vbufOIeVmxcU9Dl2QXE6FUfbeWV7jT/AG2N4\ndmMldz2/nZKCFD7pXZxuXEY8nzm3kH+XHubS37/LqzuqKUiLZeOhY0GtVXOgvpWm9m7m9Anunk3l\nnlxfwZPrK7hhXi6XTMns98PqbKHBXakRtqAolbzUGBZN6LMzZchdOzuXLpeb0vKjfSpleiopSOG7\nSybx0K3zKUqPIynGznkT0nllW3WvQPn2nlpcbsOHpwROyfjMLfCkOU6uaKk42sbzW46wbH4+SbF9\nU0xLp2eTnxrLFx9ez7X3vM8TpYe59p73+fq/N1GQFsfvbpjZa83+r1xcTGZCNDnJMbzwlQu4ZVER\n9cc7OdLUexmBn7+4k289vrnXcxvKj3rb2ju4T81OJCnGzu9f2wPAlxZPYF5hCh3dgT+szhZBBXcR\nWSIiu0Vkn4h8P8Dx34vIJu+fPSKiW8IoFSSb1cKb31rM7UNcGTQY03MSmTDGU2EzUHC3WITbF0/o\nte3hkmlZHGxoY3ePma6v76wlLc7BrNy+e/32lJEQRWFaLOtOGlS9f2UZAtxyflG/v/f6Ny/kZ9dM\np6apg+88uYXDje38+voZPHfHIv/Wij5JMXbe/s5iVnx5EZOyEpjpXZKh5/6ybrfhyfUVPLupslcl\nzvryoyTH2hl30rIZFotw7rg0nG7DdXNyyUmOoaQw8IfV2WTQ4C4iVuDPwFJgKrBMRKb2PMcY8w3v\nDkyzgD8BTw9HY5WKVHar5YysByQiXDM7B6DX7NZgXDo1ExF4eZsnNfP27lpe2FLFFTOye/We+1NS\nmEqpd2lkgKOtXfx73WGumjWWsQMsdOewWbhpQQFvfWcxj3x+AW99+0JuKMnr9zWj7Vb/3+WU7ATs\nVum1icme2hYaW7twuQ1vevfRBVh/6Chz81MC3odLvPX/ty/2VNFkJERRlB7HB2X9VwCNtGB67vOB\nfcaYA8aYLuAx4OoBzl+GZx9VpdRZ6OYFBXzhwnGcf4ppoIyEKOYVpPLytmoO1rfy1Uc3Mikzge8t\nnRzU788rTOFoWzf761oxxvDT/+ygvdvFbR8aF9TvR9msLJqQHnCLxYF+Z2p2Yq+e+xpvWWNCtI1X\nt3sqfY61dbGv9niffLvPdXNyWPejS/yb64AndbW+vPGUl2o4U4IJ7jlAz00kK7zP9SEiBUAR8GY/\nx28TkVIRKa2rO/PTipVSkBRr5wdLpxDjOPX1fz4yPYtd1S186oG1WCzC3z5dEvSkuZ6pjP99bQ9P\nb6jkaxcX99o1bDjMzEtma0WTf12e1QcayEuN4WOzcnhnTx0d3S42ejdUmRNgAhh4vvGcvCT1vKJU\n74fV8WFt/+kKJrgH+u7T30fVjcCTxpiAU7eMMfcZY0qMMSUZGWdmiVelVOh8ZJqnKqbyaDt//uSc\nU1qAbVx6HKlxDu5+ax9/enMfnyjJ4+uXFA9XU/1m5ibT2uVif91x3G7D2rJGzh2XxmXTMmnvdrFy\nbz3ry49itQgz84Lfx9hXC+8bR9hXe5yb71/L71/bc1ZsWRjMR24F0HPXhVygv4UnbgTuGGqjlFJn\np9yUWL60eDzFY+JPubpHRJhbkMJrO2pYPCmD/7lm+hkZZ/ANqm46fIxul5tjbd2cOz6NBUVp3tRM\nNRVH25manXhKS3cUpsWSHh9F6cFGFk1I46b719DS4eS9/fX88c29XFCcway8ZHJTYshPjaWkIKXX\nctDDLZh3sg4oFpEioBJPAP/kySeJyCQgBVgd0hYqpc4q31sSXI49kBvn5eGwWvj19TP8e9AOt3Hp\ncSRE2dh8+BjN3sXLFo5Lw2GzcPHkMby+s4ZOp5uP91j6IBgiwrzCFFbtq2dtWSNdTjfP3L6IWIeV\nJ9ZX8NymSlburcNXOXrx5DHc+6m5Z+x9DxrcjTFOEfky8ApgBR4wxmwXkbuAUmPMCu+py4DHjO5s\nq5Tqx8VTMvtdFnm4WCzCjLwktlQ0UdPcQWFaLNlJnuqcy6Zl+dfp6W8wdSAlham8tK2ahGgbj/7X\nQn956Tcvncg3L51Il9NNdVMHL207wi9e2sXX/72JP944u9dOXsMlqO8gxpgXgRdPeu7HJz3+Seia\npZRSoTMzN5n73j3AwXorV8zM9j9/4cQMHDYLXU73Kc/4BVgyPYs3d9XwrcsmMT3AukAOm4X8tFi+\ncOF4LCL87MWdRNus/Ob6GUGVjw6Frg2rlIp4M/OScboNLZ1OFnq3HwTPevkXTsxgR1XzaW0qn5Mc\nwyOfXxjUuf/1oXG0dbn4/et7SE9w8IOlU0759U6FBnelVMTzbR4O+PeW9fnVdTNo6eg+I4O7X714\nAjarDLoWTyhocFdKRbzMxGiyEqOJjbIyJjG617HUOAepcY4z0g4R4Y6LJpyR19LgrpQaFX5w+eSz\neuP2UNPgrpQaFa6eFXBifcTSJX+VUioCaXBXSqkIpMFdKaUikAZ3pZSKQBrclVIqAmlwV0qpCKTB\nXSmlIpAGd6WUikAyUiv0ikgdUH6av54O1IewOeFiNL7v0fieYXS+79H4nuHU33eBMWbQrexGLLgP\nhYiUGmNKRrodZ9pofN+j8T3D6Hzfo/E9w/C9b03LKKVUBNLgrpRSEShcg/t9I92AETIa3/dofM8w\nOt/3aHzPMEzvOyxz7koppQYWrj13pZRSAwi74C4iS0Rkt4jsE5Hvj3R7hoOI5InIWyKyU0S2i8jX\nvM+nishrIrLX+99T39E3DIiIVUQ2isgL3sdFIrLW+77/LSJnZtucM0REkkXkSRHZ5b3n546Gey0i\n3/D++94mIo+KSHQk3msReUBEakVkW4/nAt5f8fijN75tEZE5p/u6YRXcRcQK/BlYCkwFlonI1JFt\n1bBwAt8yxkwBFgJ3eN/n94E3jDHFwBvex5Hoa8DOHo9/Bfze+76PAreOSKuGz/8BLxtjJgMz8bz3\niL7XIpIDfBUoMcZMB6zAjUTmvV4OLDnpuf7u71Kg2PvnNuCe033RsAruwHxgnzHmgDGmC3gMuHqE\n2xRyxpgjxpgN3p9b8PzPnoPnvf7Te9o/gY+NTAuHj4jkAh8F7vc+FuDDwJPeUyLqfYtIIvAh4O8A\nxpguY8wxRsG9xrMTXIyI2IBY4AgReK+NMe8CjSc93d/9vRp40HisAZJFJPt0XjfcgnsOcLjH4wrv\ncxFLRAqB2cBaINMYcwQ8HwDAmJFr2bD5A/BdwO19nAYcM8Y4vY8j7Z6PA+qAf3hTUfeLSBwRfq+N\nMZXAb4FDeIJ6E7CeyL7XPfV3f0MW48ItuEuA5yK23EdE4oGngK8bY5pHuj3DTUSuAGqNMet7Ph3g\n1Ei65zZgDnCPMWY20EqEpWAC8eaYrwaKgLFAHJ6UxMki6V4HI2T/3sMtuFcAeT0e5wJVI9SWYSUi\ndjyB/RFjzNPep2t8X9G8/60dqfYNk0XAVSJyEE/K7cN4evLJ3q/uEHn3vAKoMMas9T5+Ek+wj/R7\nfQlQZoypM8Z0A08D5xHZ97qn/u5vyGJcuAX3dUCxd0TdgWcAZsUItynkvHnmvwM7jTH/2+PQCuAz\n3p8/Azx3pts2nIwxPzDG5BpjCvHc2zeNMTcBbwHXe0+LqPdtjKkGDovIJO9TFwM7iPB7jScds1BE\nYr3/3n3vO2Lv9Un6u78rgE97q2YWAk2+9M0pM8aE1R/gcmAPsB/475FuzzC9x/PxfBXbAmzy/rkc\nT/75DWCv97+pI93WYfw7WAy84P15HPABsA94Aoga6faF+L3OAkq99/tZIGU03Gvg/wG7gG3AQ0BU\nJN5r4FE84wrdeHrmt/Z3f/GkZf7sjW9b8VQTndbr6gxVpZSKQOGWllFKKRUEDe5KKRWBNLgrpVQE\n0uCulFIRSIO7UkpFIA3uSikVgTS4K6VUBNLgrpRSEej/A0DBxYyglg0YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f9f714c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3955, -1.3778, -6.7090, -2.6287, -6.7912]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    output = []\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    return output\n",
    "evaluate(review_to_tensor(reviews[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "        \n",
    "predictions = open(\"rnn_prediction_category1.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(review_to_tensor(l['reviewText']))\n",
    "    if len(output) == 0:\n",
    "        cat = 0\n",
    "    else:\n",
    "        cat = categoryFromOutput(output)\n",
    "    predictions.write(l['reviewerID'] + '-' + l['reviewHash'] + \",\" + str(cat) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72775\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for l in data[:20000]:\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(review_to_tensor(l['reviewText']))\n",
    "        if len(output) == 0:\n",
    "            cat = 0\n",
    "        else:\n",
    "            cat = categoryFromOutput(output)\n",
    "    predictions.append(cat)\n",
    "correct = [(a==b) for (a,b) in zip(predictions, y[:20000])]\n",
    "print(np.sum(correct)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
